{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5f497-2c72-422b-86f7-06ad8842fd6d",
   "metadata": {},
   "source": [
    "# Challenge 1: Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b48ba0-101f-4611-b8bc-b4d8e05ab2f5",
   "metadata": {},
   "source": [
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the following links: \n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2_clean.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3_clean.csv\n",
    "\n",
    "Combine the data from the three dataframes into a single dataframe, named \"customer_data\", using appropriate merging, concatenating, and joining techniques.\n",
    "\n",
    "Verify that the customer_data dataframe contains all the rows and columns from the three original dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {},
   "source": [
    "## Alternative - Bonus\n",
    "\n",
    "If in the previous lab you created your cleaning and formatting function, or if you want to do it now, instead of using the two clean files provided above, you can use your function to clean and format the data in these two raw files, and work with your clean files instead:\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Observation: \n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "  Customer          ST GENDER             Education Customer Lifetime Value  \\\n",
      "0  RB50392  Washington    NaN                Master                     NaN   \n",
      "1  QZ44356     Arizona      F              Bachelor              697953.59%   \n",
      "2  AI49188      Nevada      F              Bachelor             1288743.17%   \n",
      "3  WW63253  California      M              Bachelor              764586.18%   \n",
      "4  GA49547  Washington      M  High School or Below              536307.65%   \n",
      "\n",
      "    Income  Monthly Premium Auto Number of Open Complaints     Policy Type  \\\n",
      "0      0.0                1000.0                    1/0/00   Personal Auto   \n",
      "1      0.0                  94.0                    1/0/00   Personal Auto   \n",
      "2  48767.0                 108.0                    1/0/00   Personal Auto   \n",
      "3      0.0                 106.0                    1/0/00  Corporate Auto   \n",
      "4  36357.0                  68.0                    1/0/00   Personal Auto   \n",
      "\n",
      "   Vehicle Class  Total Claim Amount  \n",
      "0  Four-Door Car            2.704934  \n",
      "1  Four-Door Car         1131.464935  \n",
      "2   Two-Door Car          566.472247  \n",
      "3            SUV          529.881344  \n",
      "4  Four-Door Car           17.269323  \n",
      "\n",
      "DataFrame 2:\n",
      "  Customer          ST GENDER             Education Customer Lifetime Value  \\\n",
      "0  RB50392  Washington    NaN                Master                     NaN   \n",
      "1  QZ44356     Arizona      F              Bachelor              697953.59%   \n",
      "2  AI49188      Nevada      F              Bachelor             1288743.17%   \n",
      "3  WW63253  California      M              Bachelor              764586.18%   \n",
      "4  GA49547  Washington      M  High School or Below              536307.65%   \n",
      "\n",
      "    Income  Monthly Premium Auto Number of Open Complaints     Policy Type  \\\n",
      "0      0.0                1000.0                    1/0/00   Personal Auto   \n",
      "1      0.0                  94.0                    1/0/00   Personal Auto   \n",
      "2  48767.0                 108.0                    1/0/00   Personal Auto   \n",
      "3      0.0                 106.0                    1/0/00  Corporate Auto   \n",
      "4  36357.0                  68.0                    1/0/00   Personal Auto   \n",
      "\n",
      "   Vehicle Class  Total Claim Amount  \n",
      "0  Four-Door Car            2.704934  \n",
      "1  Four-Door Car         1131.464935  \n",
      "2   Two-Door Car          566.472247  \n",
      "3            SUV          529.881344  \n",
      "4  Four-Door Car           17.269323  \n",
      "\n",
      "DataFrame 3:\n",
      "  Customer          ST GENDER             Education Customer Lifetime Value  \\\n",
      "0  RB50392  Washington    NaN                Master                     NaN   \n",
      "1  QZ44356     Arizona      F              Bachelor              697953.59%   \n",
      "2  AI49188      Nevada      F              Bachelor             1288743.17%   \n",
      "3  WW63253  California      M              Bachelor              764586.18%   \n",
      "4  GA49547  Washington      M  High School or Below              536307.65%   \n",
      "\n",
      "    Income  Monthly Premium Auto Number of Open Complaints     Policy Type  \\\n",
      "0      0.0                1000.0                    1/0/00   Personal Auto   \n",
      "1      0.0                  94.0                    1/0/00   Personal Auto   \n",
      "2  48767.0                 108.0                    1/0/00   Personal Auto   \n",
      "3      0.0                 106.0                    1/0/00  Corporate Auto   \n",
      "4  36357.0                  68.0                    1/0/00   Personal Auto   \n",
      "\n",
      "   Vehicle Class  Total Claim Amount  \n",
      "0  Four-Door Car            2.704934  \n",
      "1  Four-Door Car         1131.464935  \n",
      "2   Two-Door Car          566.472247  \n",
      "3            SUV          529.881344  \n",
      "4  Four-Door Car           17.269323  \n",
      "[['df_file1', 'df_file2', 'df_file3']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url_file1 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\"\n",
    "url_file2 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2_clean.csv\"\n",
    "url_file3 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3_clean.csv\"\n",
    "\n",
    "df_file1 = pd.read_csv(url_file1)\n",
    "df_file2 = pd.read_csv(url_file2)\n",
    "df_file3 = pd.read_csv(url_file3)\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df_file1.head())\n",
    "\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df_file2.head())\n",
    "\n",
    "print(\"\\nDataFrame 3:\")\n",
    "print(df_file3.head())\n",
    "\n",
    "customer_data = [['df_file1', 'df_file2', 'df_file3']]\n",
    "\n",
    "print(customer_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.concat([df_file1, df_file2, df_file3], ignore_index=True)\n",
    "\n",
    "print(\"\\nCombined DataFrame:\")\n",
    "print(customer_data.head())\n",
    "print(customer_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {},
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {},
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_pivot.reindex(df_pivot.sort_values(by='customer_lifetime_value', ascending=False).index)\n",
    "Maybe try this Philipp to sort the pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {},
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {},
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {},
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activities List\n",
    "Important: for Activity 3 and Activity 4 , please use the file Data_Marketing_Customer_Analysis_Round3.csv from the Data folder.\n",
    "\n",
    "Activity 3 (Wednesday)\n",
    "As a reminder the objective of this study is to predict the total claim amount of a customer and study/investigate the impact of the factors (input features) on the target variable(total claim amount). That means in your exploratory data analysis, you have to look for patterns in this data that show interesting relationships among the input features as well as with relation to the target feature.\n",
    "\n",
    "Get the numeric data into a dataframe called numerical and categorical columns in a dataframe called categorical. (You can use \"np.number\" and \"object\" to select the numerical data types and categorical data types respectively)\n",
    "Now we will try to check the normality of the numerical variables visually\n",
    "Use the Seaborn library to construct distribution plots for the numerical variables\n",
    "Use the Matplotlib library to construct histograms.\n",
    "Do the distributions for different numerical variables look like a normal distribution?\n",
    "For the numerical variables, check for correlation between the input features. Note: this does not include the target feature.\n",
    "Plot the Correlation Heatmap.\n",
    "(Optional): Drop one of the two features that show a high correlation between them (greater than 0.9). If there is no pair of features that have a high correlation, then do not drop any features.\n",
    "Activity 4 (Thursday)\n",
    "Show a plot of the total number of responses.\n",
    "Show a plot of the response by the sales channel.\n",
    "Show a plot of the response by the total claim amount.\n",
    "Show a plot of the response by income.\n",
    "(Optional) plot any interesting findings/insights(minimum three) that describe some interesting facts about your data set and its input variables as well as relationships with the target feature.\n",
    "Clean your notebook and make it readable and presentable with a good documentation that summarizes the Data Cleaning, Exploration(including plots), Steps that you have performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "074ea79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame_:\n",
      "        region  customer_lifetime_value response  coverage education  \\\n",
      "0      central                     4809       no     basic   college   \n",
      "1  west region                     2228       no     basic   college   \n",
      "2         east                    14947       no     basic  bachelor   \n",
      "3   north west                    22332      yes  extended   college   \n",
      "4   north west                     9025       no   premium  bachelor   \n",
      "\n",
      "  effective_to_date month employment_status gender  income  ...  \\\n",
      "0           2/18/11   feb          employed      m   48029  ...   \n",
      "1           1/18/11   jan        unemployed      f   92260  ...   \n",
      "2           2/10/11   feb          employed      m   22139  ...   \n",
      "3           1/11/11   jan          employed      m   49078  ...   \n",
      "4           1/17/11   jan     medical leave      f   23675  ...   \n",
      "\n",
      "  months_since_policy_inception number_of_open_complaints  number_of_policies  \\\n",
      "0                            52                         0                   9   \n",
      "1                            26                         0                   1   \n",
      "2                            31                         0                   2   \n",
      "3                             3                         0                   2   \n",
      "4                            31                         0                   7   \n",
      "\n",
      "      policy_type        policy  renew_offer_type  sales_channel  \\\n",
      "0  corporate auto  corporate l3            offer3          agent   \n",
      "1   personal auto   personal l3            offer4    call center   \n",
      "2   personal auto   personal l3            offer3    call center   \n",
      "3  corporate auto  corporate l3            offer2         branch   \n",
      "4   personal auto   personal l2            offer1         branch   \n",
      "\n",
      "  total_claim_amount  vehicle_class vehicle_size  \n",
      "0                292  four-door car      medsize  \n",
      "1                744  four-door car      medsize  \n",
      "2                480            suv      medsize  \n",
      "3                484  four-door car      medsize  \n",
      "4                707  four-door car      medsize  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data_path = \"Data_Marketing_Customer_Analysis_Round3.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"DataFrame_:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ac0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
